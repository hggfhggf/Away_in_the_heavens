{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "483eebb9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-18T14:21:03.725388Z",
     "iopub.status.busy": "2025-10-18T14:21:03.724665Z",
     "iopub.status.idle": "2025-10-18T14:21:08.299215Z",
     "shell.execute_reply": "2025-10-18T14:21:08.298222Z"
    },
    "executionInfo": {
     "elapsed": 8909,
     "status": "ok",
     "timestamp": 1742919234880,
     "user": {
      "displayName": "Ильсеяр Алимова",
      "userId": "18086433180291504366"
     },
     "user_tz": -180
    },
    "id": "5db35d05",
    "papermill": {
     "duration": 4.582544,
     "end_time": "2025-10-18T14:21:08.300949",
     "exception": false,
     "start_time": "2025-10-18T14:21:03.718405",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d756ec5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-18T14:21:08.313140Z",
     "iopub.status.busy": "2025-10-18T14:21:08.312430Z",
     "iopub.status.idle": "2025-10-18T14:21:08.321419Z",
     "shell.execute_reply": "2025-10-18T14:21:08.320592Z"
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1742919234895,
     "user": {
      "displayName": "Ильсеяр Алимова",
      "userId": "18086433180291504366"
     },
     "user_tz": -180
    },
    "id": "cMV0vTRfAN0I",
    "papermill": {
     "duration": 0.015859,
     "end_time": "2025-10-18T14:21:08.323003",
     "exception": false,
     "start_time": "2025-10-18T14:21:08.307144",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22221a6a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-18T14:21:08.332994Z",
     "iopub.status.busy": "2025-10-18T14:21:08.332375Z",
     "iopub.status.idle": "2025-10-18T14:21:12.858014Z",
     "shell.execute_reply": "2025-10-18T14:21:12.856978Z"
    },
    "executionInfo": {
     "elapsed": 10285,
     "status": "ok",
     "timestamp": 1742919245186,
     "user": {
      "displayName": "Ильсеяр Алимова",
      "userId": "18086433180291504366"
     },
     "user_tz": -180
    },
    "id": "iAtJ_d5W5T7Y",
    "outputId": "15623f72-b00c-42db-abfc-58a8e5e907f5",
    "papermill": {
     "duration": 4.532369,
     "end_time": "2025-10-18T14:21:12.859765",
     "exception": false,
     "start_time": "2025-10-18T14:21:08.327396",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading...\r\n",
      "From: https://drive.google.com/uc?id=1k1quangHHsq25rJOTLShK3H0hN1mVqp9\r\n",
      "To: /kaggle/working/train.csv\r\n",
      "100%|██████████████████████████████████████| 38.0k/38.0k [00:00<00:00, 57.5MB/s]\r\n",
      "Downloading...\r\n",
      "From: https://drive.google.com/uc?id=1NsJXT6eBrXDKXKggfWjwcYuoU84CII3g\r\n",
      "To: /kaggle/working/test.csv\r\n",
      "100%|████████████████████████████████████████| 134k/134k [00:00<00:00, 77.9MB/s]\r\n"
     ]
    }
   ],
   "source": [
    "!gdown --fuzzy https://drive.google.com/file/d/1k1quangHHsq25rJOTLShK3H0hN1mVqp9/view?usp=sharing -O train.csv\n",
    "!gdown --fuzzy https://drive.google.com/file/d/1NsJXT6eBrXDKXKggfWjwcYuoU84CII3g/view?usp=drive_link -O test.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0590c5b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-18T14:21:12.870759Z",
     "iopub.status.busy": "2025-10-18T14:21:12.870163Z",
     "iopub.status.idle": "2025-10-18T14:21:14.646374Z",
     "shell.execute_reply": "2025-10-18T14:21:14.645497Z"
    },
    "id": "c4bc7518",
    "papermill": {
     "duration": 1.783478,
     "end_time": "2025-10-18T14:21:14.648047",
     "exception": false,
     "start_time": "2025-10-18T14:21:12.864569",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "train_dataset = pd.read_csv('train.csv').values\n",
    "test_dataset = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1d66a68",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-18T14:21:14.658083Z",
     "iopub.status.busy": "2025-10-18T14:21:14.657585Z",
     "iopub.status.idle": "2025-10-18T14:21:14.664099Z",
     "shell.execute_reply": "2025-10-18T14:21:14.663390Z"
    },
    "papermill": {
     "duration": 0.01287,
     "end_time": "2025-10-18T14:21:14.665368",
     "exception": false,
     "start_time": "2025-10-18T14:21:14.652498",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['den tjugofjärde 05 2049', '24-05-2049'],\n",
       "       ['15/11/77', '15-11-2077'],\n",
       "       [\"sipsa'e 02 2049\", '14-02-2049'],\n",
       "       ...,\n",
       "       ['le neuf mars 2007', '09-03-2007'],\n",
       "       ['am vier und zwanzigsten juni 2007', '24-06-2007'],\n",
       "       ['sechster juni 2007', '06-06-2007']], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e151840",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-18T14:21:14.675854Z",
     "iopub.status.busy": "2025-10-18T14:21:14.675200Z",
     "iopub.status.idle": "2025-10-18T14:21:14.700333Z",
     "shell.execute_reply": "2025-10-18T14:21:14.699517Z"
    },
    "papermill": {
     "duration": 0.031738,
     "end_time": "2025-10-18T14:21:14.701607",
     "exception": false,
     "start_time": "2025-10-18T14:21:14.669869",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>24 января 2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>le six mars 2049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>le dix 05 2077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>27 июня 2049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>08 гыйнварда 2077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4671</th>\n",
       "      <td>4671</td>\n",
       "      <td>am fünfzehnten januar 2049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4672</th>\n",
       "      <td>4672</td>\n",
       "      <td>тугызынчы 05 2049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4673</th>\n",
       "      <td>4673</td>\n",
       "      <td>der achzehnte 02 2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4674</th>\n",
       "      <td>4674</td>\n",
       "      <td>vierzehnter 12 2049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4675</th>\n",
       "      <td>4675</td>\n",
       "      <td>20/01/77</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4676 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                        data\n",
       "0        0              24 января 2007\n",
       "1        1            le six mars 2049\n",
       "2        2              le dix 05 2077\n",
       "3        3                27 июня 2049\n",
       "4        4           08 гыйнварда 2077\n",
       "...    ...                         ...\n",
       "4671  4671  am fünfzehnten januar 2049\n",
       "4672  4672           тугызынчы 05 2049\n",
       "4673  4673       der achzehnte 02 2007\n",
       "4674  4674         vierzehnter 12 2049\n",
       "4675  4675                    20/01/77\n",
       "\n",
       "[4676 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2179e2a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-18T14:21:14.712342Z",
     "iopub.status.busy": "2025-10-18T14:21:14.711767Z",
     "iopub.status.idle": "2025-10-18T14:21:14.717739Z",
     "shell.execute_reply": "2025-10-18T14:21:14.716870Z"
    },
    "id": "76a5c735",
    "outputId": "2083b5f5-3fba-4ee3-ecc4-102ff4aaeea9",
    "papermill": {
     "duration": 0.012616,
     "end_time": "2025-10-18T14:21:14.718966",
     "exception": false,
     "start_time": "2025-10-18T14:21:14.706350",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_LENGTH = max(map(lambda x: len(x[0]), train_dataset)) + 1\n",
    "\n",
    "MAX_LENGTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d38c28c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-18T14:21:14.729866Z",
     "iopub.status.busy": "2025-10-18T14:21:14.729234Z",
     "iopub.status.idle": "2025-10-18T14:21:14.735319Z",
     "shell.execute_reply": "2025-10-18T14:21:14.734467Z"
    },
    "id": "556ae6af",
    "papermill": {
     "duration": 0.012983,
     "end_time": "2025-10-18T14:21:14.736676",
     "exception": false,
     "start_time": "2025-10-18T14:21:14.723693",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "\n",
    "class Lang:\n",
    "\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {\n",
    "            'SOS': 0,\n",
    "            'EOS': 1\n",
    "        }\n",
    "        self.index2word = {\n",
    "            0: 'SOS',\n",
    "            1: 'EOS'\n",
    "        }\n",
    "\n",
    "    @property\n",
    "    def n_words(self) -> int:\n",
    "        return len(self.index2word)\n",
    "\n",
    "    def add_sentence(self, sentence):\n",
    "        for word in list(sentence):\n",
    "            self.add_word(word)\n",
    "\n",
    "    def add_word(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.index2word[self.n_words] = word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "154df63c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-18T14:21:14.747584Z",
     "iopub.status.busy": "2025-10-18T14:21:14.746887Z",
     "iopub.status.idle": "2025-10-18T14:21:14.756336Z",
     "shell.execute_reply": "2025-10-18T14:21:14.755613Z"
    },
    "id": "74410a56",
    "outputId": "a84b06f1-37ea-4152-da4d-6346b5d36ee3",
    "papermill": {
     "duration": 0.016162,
     "end_time": "2025-10-18T14:21:14.757639",
     "exception": false,
     "start_time": "2025-10-18T14:21:14.741477",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "human 82\n",
      "iso 13\n"
     ]
    }
   ],
   "source": [
    "input_lang = Lang('human')\n",
    "output_lang = Lang('iso')\n",
    "\n",
    "for pair in train_dataset:\n",
    "    input_lang.add_sentence(pair[0])\n",
    "    output_lang.add_sentence(pair[1])\n",
    "\n",
    "print(input_lang.name, input_lang.n_words)\n",
    "print(output_lang.name, output_lang.n_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c28883a1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-18T14:21:14.768512Z",
     "iopub.status.busy": "2025-10-18T14:21:14.767923Z",
     "iopub.status.idle": "2025-10-18T14:21:14.774079Z",
     "shell.execute_reply": "2025-10-18T14:21:14.773377Z"
    },
    "id": "b5e4f21a",
    "papermill": {
     "duration": 0.013248,
     "end_time": "2025-10-18T14:21:14.775592",
     "exception": false,
     "start_time": "2025-10-18T14:21:14.762344",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d32492c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-18T14:21:14.786281Z",
     "iopub.status.busy": "2025-10-18T14:21:14.785979Z",
     "iopub.status.idle": "2025-10-18T14:21:14.791763Z",
     "shell.execute_reply": "2025-10-18T14:21:14.790824Z"
    },
    "id": "8fe0f376",
    "papermill": {
     "duration": 0.012723,
     "end_time": "2025-10-18T14:21:14.793125",
     "exception": false,
     "start_time": "2025-10-18T14:21:14.780402",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        embedded = self.embedding(x).view(1, 1, -1)\n",
    "        output = embedded\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ca3aad1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-18T14:21:14.803790Z",
     "iopub.status.busy": "2025-10-18T14:21:14.803466Z",
     "iopub.status.idle": "2025-10-18T14:21:14.809764Z",
     "shell.execute_reply": "2025-10-18T14:21:14.809022Z"
    },
    "id": "42832f9b",
    "papermill": {
     "duration": 0.013194,
     "end_time": "2025-10-18T14:21:14.811009",
     "exception": false,
     "start_time": "2025-10-18T14:21:14.797815",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        output = self.embedding(x).view(1, 1, -1)\n",
    "        output = self.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "96ee91d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-18T14:21:14.822856Z",
     "iopub.status.busy": "2025-10-18T14:21:14.822113Z",
     "iopub.status.idle": "2025-10-18T14:21:14.827510Z",
     "shell.execute_reply": "2025-10-18T14:21:14.826832Z"
    },
    "id": "d3308116",
    "papermill": {
     "duration": 0.013089,
     "end_time": "2025-10-18T14:21:14.828866",
     "exception": false,
     "start_time": "2025-10-18T14:21:14.815777",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sentence2idx(lang, sentence):\n",
    "    return [lang.word2index[word] for word in list(sentence)]\n",
    "\n",
    "\n",
    "def sentence2tensor(lang, sentence):\n",
    "    indexes = sentence2idx(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
    "\n",
    "\n",
    "def pair2tensor(x):\n",
    "    input_tensor = sentence2tensor(input_lang, x[0])\n",
    "    target_tensor = sentence2tensor(output_lang, x[1])\n",
    "    return input_tensor, target_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "750cb2fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-18T14:21:14.839836Z",
     "iopub.status.busy": "2025-10-18T14:21:14.839213Z",
     "iopub.status.idle": "2025-10-18T14:21:14.845970Z",
     "shell.execute_reply": "2025-10-18T14:21:14.845167Z"
    },
    "id": "2ff20461",
    "papermill": {
     "duration": 0.013606,
     "end_time": "2025-10-18T14:21:14.847285",
     "exception": false,
     "start_time": "2025-10-18T14:21:14.833679",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_single(\n",
    "        input_tensor, target_tensor,\n",
    "        encoder, decoder,\n",
    "        encoder_optimizer, decoder_optimizer,\n",
    "        criterion\n",
    "):\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    encoder_hidden = encoder.init_hidden()\n",
    "\n",
    "    for elem in input_tensor:\n",
    "        encoder_output, encoder_hidden = encoder(elem, encoder_hidden)\n",
    "\n",
    "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    use_teacher_forcing = False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        for elem in target_tensor:\n",
    "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "            loss += criterion(decoder_output, elem)\n",
    "            decoder_input = elem\n",
    "    else:\n",
    "        for elem in target_tensor:\n",
    "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "            _, topi = decoder_output.data.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "\n",
    "            loss += criterion(decoder_output, elem)\n",
    "            if decoder_input.item() == EOS_token:\n",
    "                break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / len(target_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "af686524",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-18T14:21:14.858083Z",
     "iopub.status.busy": "2025-10-18T14:21:14.857794Z",
     "iopub.status.idle": "2025-10-18T14:21:14.864144Z",
     "shell.execute_reply": "2025-10-18T14:21:14.863422Z"
    },
    "id": "99270fd7",
    "papermill": {
     "duration": 0.013364,
     "end_time": "2025-10-18T14:21:14.865502",
     "exception": false,
     "start_time": "2025-10-18T14:21:14.852138",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(encoder, decoder, n_epochs=5, print_every=100):\n",
    "    encoder.train()\n",
    "    decoder.train()\n",
    "\n",
    "    encoder_optimizer = Adam(encoder.parameters(), lr=1e-3)\n",
    "    decoder_optimizer = Adam(decoder.parameters(), lr=1e-3)\n",
    "\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        print_loss_total = 0\n",
    "\n",
    "        print(f'Epoch [{epoch + 1:02d}/{n_epochs:02d}]')\n",
    "        training_pairs = [\n",
    "            pair2tensor(x) for x in train_dataset\n",
    "        ]\n",
    "\n",
    "        for i, training_pair in enumerate(training_pairs):\n",
    "            input_tensor = training_pair[0]\n",
    "            target_tensor = training_pair[1]\n",
    "\n",
    "            loss = train_single(\n",
    "                input_tensor, target_tensor,\n",
    "                encoder, decoder,\n",
    "                encoder_optimizer, decoder_optimizer,\n",
    "                criterion\n",
    "            )\n",
    "            print_loss_total += loss\n",
    "\n",
    "            if (i + 1) % print_every == 0:\n",
    "                print_loss_avg = print_loss_total / print_every\n",
    "                print_loss_total = 0\n",
    "                print(f'Training ({i / len(training_pairs) * 100:.1f}%) loss: {print_loss_avg:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c3ea2060",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-18T14:21:14.876158Z",
     "iopub.status.busy": "2025-10-18T14:21:14.875859Z",
     "iopub.status.idle": "2025-10-18T14:39:36.494934Z",
     "shell.execute_reply": "2025-10-18T14:39:36.493914Z"
    },
    "id": "0c3f5df8",
    "outputId": "a2a19cc9-bea8-453d-abc9-38c57e7dc5a7",
    "papermill": {
     "duration": 1101.626474,
     "end_time": "2025-10-18T14:39:36.496738",
     "exception": false,
     "start_time": "2025-10-18T14:21:14.870264",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [01/40]\n",
      "Training (9.0%) loss: 1.8857\n",
      "Training (18.2%) loss: 1.3371\n",
      "Training (27.3%) loss: 0.7938\n",
      "Training (36.4%) loss: 0.6853\n",
      "Training (45.6%) loss: 0.6303\n",
      "Training (54.7%) loss: 0.6155\n",
      "Training (63.8%) loss: 0.5840\n",
      "Training (73.0%) loss: 0.5784\n",
      "Training (82.1%) loss: 0.5457\n",
      "Training (91.2%) loss: 0.5270\n",
      "Epoch [02/40]\n",
      "Training (9.0%) loss: 0.5198\n",
      "Training (18.2%) loss: 0.5283\n",
      "Training (27.3%) loss: 0.5029\n",
      "Training (36.4%) loss: 0.4867\n",
      "Training (45.6%) loss: 0.4639\n",
      "Training (54.7%) loss: 0.4775\n",
      "Training (63.8%) loss: 0.4447\n",
      "Training (73.0%) loss: 0.4359\n",
      "Training (82.1%) loss: 0.4154\n",
      "Training (91.2%) loss: 0.4034\n",
      "Epoch [03/40]\n",
      "Training (9.0%) loss: 0.4006\n",
      "Training (18.2%) loss: 0.4036\n",
      "Training (27.3%) loss: 0.3850\n",
      "Training (36.4%) loss: 0.3510\n",
      "Training (45.6%) loss: 0.3396\n",
      "Training (54.7%) loss: 0.3440\n",
      "Training (63.8%) loss: 0.3211\n",
      "Training (73.0%) loss: 0.3268\n",
      "Training (82.1%) loss: 0.3101\n",
      "Training (91.2%) loss: 0.3001\n",
      "Epoch [04/40]\n",
      "Training (9.0%) loss: 0.2832\n",
      "Training (18.2%) loss: 0.2877\n",
      "Training (27.3%) loss: 0.2715\n",
      "Training (36.4%) loss: 0.2482\n",
      "Training (45.6%) loss: 0.3223\n",
      "Training (54.7%) loss: 0.2830\n",
      "Training (63.8%) loss: 0.2344\n",
      "Training (73.0%) loss: 0.2219\n",
      "Training (82.1%) loss: 0.2112\n",
      "Training (91.2%) loss: 0.1994\n",
      "Epoch [05/40]\n",
      "Training (9.0%) loss: 0.2005\n",
      "Training (18.2%) loss: 0.1955\n",
      "Training (27.3%) loss: 0.1913\n",
      "Training (36.4%) loss: 0.1689\n",
      "Training (45.6%) loss: 0.1714\n",
      "Training (54.7%) loss: 0.1637\n",
      "Training (63.8%) loss: 0.1566\n",
      "Training (73.0%) loss: 0.1481\n",
      "Training (82.1%) loss: 0.1513\n",
      "Training (91.2%) loss: 0.1574\n",
      "Epoch [06/40]\n",
      "Training (9.0%) loss: 0.1330\n",
      "Training (18.2%) loss: 0.1232\n",
      "Training (27.3%) loss: 0.1164\n",
      "Training (36.4%) loss: 0.1351\n",
      "Training (45.6%) loss: 0.1110\n",
      "Training (54.7%) loss: 0.1050\n",
      "Training (63.8%) loss: 0.1188\n",
      "Training (73.0%) loss: 0.0997\n",
      "Training (82.1%) loss: 0.0842\n",
      "Training (91.2%) loss: 0.1062\n",
      "Epoch [07/40]\n",
      "Training (9.0%) loss: 0.0745\n",
      "Training (18.2%) loss: 0.0788\n",
      "Training (27.3%) loss: 0.0783\n",
      "Training (36.4%) loss: 0.0720\n",
      "Training (45.6%) loss: 0.0650\n",
      "Training (54.7%) loss: 0.0629\n",
      "Training (63.8%) loss: 0.1139\n",
      "Training (73.0%) loss: 0.0664\n",
      "Training (82.1%) loss: 0.0558\n",
      "Training (91.2%) loss: 0.0713\n",
      "Epoch [08/40]\n",
      "Training (9.0%) loss: 0.0670\n",
      "Training (18.2%) loss: 0.0576\n",
      "Training (27.3%) loss: 0.0598\n",
      "Training (36.4%) loss: 0.0491\n",
      "Training (45.6%) loss: 0.0498\n",
      "Training (54.7%) loss: 0.0474\n",
      "Training (63.8%) loss: 0.0680\n",
      "Training (73.0%) loss: 0.0416\n",
      "Training (82.1%) loss: 0.0376\n",
      "Training (91.2%) loss: 0.0517\n",
      "Epoch [09/40]\n",
      "Training (9.0%) loss: 0.0541\n",
      "Training (18.2%) loss: 0.0390\n",
      "Training (27.3%) loss: 0.0331\n",
      "Training (36.4%) loss: 0.0329\n",
      "Training (45.6%) loss: 0.0423\n",
      "Training (54.7%) loss: 0.0361\n",
      "Training (63.8%) loss: 0.0445\n",
      "Training (73.0%) loss: 0.0436\n",
      "Training (82.1%) loss: 0.0292\n",
      "Training (91.2%) loss: 0.0245\n",
      "Epoch [10/40]\n",
      "Training (9.0%) loss: 0.0506\n",
      "Training (18.2%) loss: 0.0354\n",
      "Training (27.3%) loss: 0.0340\n",
      "Training (36.4%) loss: 0.0247\n",
      "Training (45.6%) loss: 0.0248\n",
      "Training (54.7%) loss: 0.0256\n",
      "Training (63.8%) loss: 0.0333\n",
      "Training (73.0%) loss: 0.0267\n",
      "Training (82.1%) loss: 0.0253\n",
      "Training (91.2%) loss: 0.0265\n",
      "Epoch [11/40]\n",
      "Training (9.0%) loss: 0.0315\n",
      "Training (18.2%) loss: 0.0247\n",
      "Training (27.3%) loss: 0.0232\n",
      "Training (36.4%) loss: 0.0121\n",
      "Training (45.6%) loss: 0.0212\n",
      "Training (54.7%) loss: 0.0200\n",
      "Training (63.8%) loss: 0.0345\n",
      "Training (73.0%) loss: 0.0175\n",
      "Training (82.1%) loss: 0.0188\n",
      "Training (91.2%) loss: 0.0270\n",
      "Epoch [12/40]\n",
      "Training (9.0%) loss: 0.0221\n",
      "Training (18.2%) loss: 0.0103\n",
      "Training (27.3%) loss: 0.0154\n",
      "Training (36.4%) loss: 0.0194\n",
      "Training (45.6%) loss: 0.0278\n",
      "Training (54.7%) loss: 0.0160\n",
      "Training (63.8%) loss: 0.0147\n",
      "Training (73.0%) loss: 0.0107\n",
      "Training (82.1%) loss: 0.0082\n",
      "Training (91.2%) loss: 0.0103\n",
      "Epoch [13/40]\n",
      "Training (9.0%) loss: 0.0155\n",
      "Training (18.2%) loss: 0.0161\n",
      "Training (27.3%) loss: 0.0347\n",
      "Training (36.4%) loss: 0.0209\n",
      "Training (45.6%) loss: 0.0141\n",
      "Training (54.7%) loss: 0.0076\n",
      "Training (63.8%) loss: 0.0091\n",
      "Training (73.0%) loss: 0.0085\n",
      "Training (82.1%) loss: 0.0049\n",
      "Training (91.2%) loss: 0.0134\n",
      "Epoch [14/40]\n",
      "Training (9.0%) loss: 0.0449\n",
      "Training (18.2%) loss: 0.0300\n",
      "Training (27.3%) loss: 0.0150\n",
      "Training (36.4%) loss: 0.0254\n",
      "Training (45.6%) loss: 0.0167\n",
      "Training (54.7%) loss: 0.0250\n",
      "Training (63.8%) loss: 0.0649\n",
      "Training (73.0%) loss: 0.0166\n",
      "Training (82.1%) loss: 0.0104\n",
      "Training (91.2%) loss: 0.0194\n",
      "Epoch [15/40]\n",
      "Training (9.0%) loss: 0.0266\n",
      "Training (18.2%) loss: 0.0092\n",
      "Training (27.3%) loss: 0.0119\n",
      "Training (36.4%) loss: 0.0179\n",
      "Training (45.6%) loss: 0.0099\n",
      "Training (54.7%) loss: 0.0110\n",
      "Training (63.8%) loss: 0.0091\n",
      "Training (73.0%) loss: 0.0071\n",
      "Training (82.1%) loss: 0.0033\n",
      "Training (91.2%) loss: 0.0041\n",
      "Epoch [16/40]\n",
      "Training (9.0%) loss: 0.0052\n",
      "Training (18.2%) loss: 0.0047\n",
      "Training (27.3%) loss: 0.0039\n",
      "Training (36.4%) loss: 0.0029\n",
      "Training (45.6%) loss: 0.0019\n",
      "Training (54.7%) loss: 0.0022\n",
      "Training (63.8%) loss: 0.0042\n",
      "Training (73.0%) loss: 0.0100\n",
      "Training (82.1%) loss: 0.0078\n",
      "Training (91.2%) loss: 0.0158\n",
      "Epoch [17/40]\n",
      "Training (9.0%) loss: 0.0052\n",
      "Training (18.2%) loss: 0.0022\n",
      "Training (27.3%) loss: 0.0033\n",
      "Training (36.4%) loss: 0.0055\n",
      "Training (45.6%) loss: 0.0079\n",
      "Training (54.7%) loss: 0.0148\n",
      "Training (63.8%) loss: 0.0347\n",
      "Training (73.0%) loss: 0.0447\n",
      "Training (82.1%) loss: 0.0224\n",
      "Training (91.2%) loss: 0.0311\n",
      "Epoch [18/40]\n",
      "Training (9.0%) loss: 0.0222\n",
      "Training (18.2%) loss: 0.0161\n",
      "Training (27.3%) loss: 0.0245\n",
      "Training (36.4%) loss: 0.0114\n",
      "Training (45.6%) loss: 0.0065\n",
      "Training (54.7%) loss: 0.0063\n",
      "Training (63.8%) loss: 0.0157\n",
      "Training (73.0%) loss: 0.0040\n",
      "Training (82.1%) loss: 0.0044\n",
      "Training (91.2%) loss: 0.0035\n",
      "Epoch [19/40]\n",
      "Training (9.0%) loss: 0.0092\n",
      "Training (18.2%) loss: 0.0171\n",
      "Training (27.3%) loss: 0.0185\n",
      "Training (36.4%) loss: 0.0100\n",
      "Training (45.6%) loss: 0.0133\n",
      "Training (54.7%) loss: 0.0150\n",
      "Training (63.8%) loss: 0.0047\n",
      "Training (73.0%) loss: 0.0096\n",
      "Training (82.1%) loss: 0.0046\n",
      "Training (91.2%) loss: 0.0035\n",
      "Epoch [20/40]\n",
      "Training (9.0%) loss: 0.0072\n",
      "Training (18.2%) loss: 0.0023\n",
      "Training (27.3%) loss: 0.0074\n",
      "Training (36.4%) loss: 0.0028\n",
      "Training (45.6%) loss: 0.0159\n",
      "Training (54.7%) loss: 0.0054\n",
      "Training (63.8%) loss: 0.0025\n",
      "Training (73.0%) loss: 0.0044\n",
      "Training (82.1%) loss: 0.0130\n",
      "Training (91.2%) loss: 0.0015\n",
      "Epoch [21/40]\n",
      "Training (9.0%) loss: 0.0042\n",
      "Training (18.2%) loss: 0.0249\n",
      "Training (27.3%) loss: 0.0122\n",
      "Training (36.4%) loss: 0.0259\n",
      "Training (45.6%) loss: 0.0099\n",
      "Training (54.7%) loss: 0.0102\n",
      "Training (63.8%) loss: 0.0059\n",
      "Training (73.0%) loss: 0.0094\n",
      "Training (82.1%) loss: 0.0086\n",
      "Training (91.2%) loss: 0.0017\n",
      "Epoch [22/40]\n",
      "Training (9.0%) loss: 0.0028\n",
      "Training (18.2%) loss: 0.0019\n",
      "Training (27.3%) loss: 0.0021\n",
      "Training (36.4%) loss: 0.0010\n",
      "Training (45.6%) loss: 0.0014\n",
      "Training (54.7%) loss: 0.0078\n",
      "Training (63.8%) loss: 0.0015\n",
      "Training (73.0%) loss: 0.0173\n",
      "Training (82.1%) loss: 0.0082\n",
      "Training (91.2%) loss: 0.0137\n",
      "Epoch [23/40]\n",
      "Training (9.0%) loss: 0.0187\n",
      "Training (18.2%) loss: 0.0072\n",
      "Training (27.3%) loss: 0.0106\n",
      "Training (36.4%) loss: 0.0247\n",
      "Training (45.6%) loss: 0.0118\n",
      "Training (54.7%) loss: 0.0050\n",
      "Training (63.8%) loss: 0.0089\n",
      "Training (73.0%) loss: 0.0068\n",
      "Training (82.1%) loss: 0.0051\n",
      "Training (91.2%) loss: 0.0038\n",
      "Epoch [24/40]\n",
      "Training (9.0%) loss: 0.0415\n",
      "Training (18.2%) loss: 0.0262\n",
      "Training (27.3%) loss: 0.0123\n",
      "Training (36.4%) loss: 0.0105\n",
      "Training (45.6%) loss: 0.0070\n",
      "Training (54.7%) loss: 0.0070\n",
      "Training (63.8%) loss: 0.0088\n",
      "Training (73.0%) loss: 0.0038\n",
      "Training (82.1%) loss: 0.0063\n",
      "Training (91.2%) loss: 0.0027\n",
      "Epoch [25/40]\n",
      "Training (9.0%) loss: 0.0027\n",
      "Training (18.2%) loss: 0.0018\n",
      "Training (27.3%) loss: 0.0054\n",
      "Training (36.4%) loss: 0.0129\n",
      "Training (45.6%) loss: 0.0028\n",
      "Training (54.7%) loss: 0.0025\n",
      "Training (63.8%) loss: 0.0177\n",
      "Training (73.0%) loss: 0.0267\n",
      "Training (82.1%) loss: 0.0108\n",
      "Training (91.2%) loss: 0.0061\n",
      "Epoch [26/40]\n",
      "Training (9.0%) loss: 0.0040\n",
      "Training (18.2%) loss: 0.1040\n",
      "Training (27.3%) loss: 0.0057\n",
      "Training (36.4%) loss: 0.0023\n",
      "Training (45.6%) loss: 0.0018\n",
      "Training (54.7%) loss: 0.0027\n",
      "Training (63.8%) loss: 0.0030\n",
      "Training (73.0%) loss: 0.0019\n",
      "Training (82.1%) loss: 0.0011\n",
      "Training (91.2%) loss: 0.0039\n",
      "Epoch [27/40]\n",
      "Training (9.0%) loss: 0.0012\n",
      "Training (18.2%) loss: 0.0047\n",
      "Training (27.3%) loss: 0.0091\n",
      "Training (36.4%) loss: 0.0018\n",
      "Training (45.6%) loss: 0.0022\n",
      "Training (54.7%) loss: 0.0039\n",
      "Training (63.8%) loss: 0.0010\n",
      "Training (73.0%) loss: 0.0014\n",
      "Training (82.1%) loss: 0.0012\n",
      "Training (91.2%) loss: 0.0012\n",
      "Epoch [28/40]\n",
      "Training (9.0%) loss: 0.0064\n",
      "Training (18.2%) loss: 0.0120\n",
      "Training (27.3%) loss: 0.0047\n",
      "Training (36.4%) loss: 0.0033\n",
      "Training (45.6%) loss: 0.0076\n",
      "Training (54.7%) loss: 0.0254\n",
      "Training (63.8%) loss: 0.0210\n",
      "Training (73.0%) loss: 0.0516\n",
      "Training (82.1%) loss: 0.0280\n",
      "Training (91.2%) loss: 0.0505\n",
      "Epoch [29/40]\n",
      "Training (9.0%) loss: 0.0289\n",
      "Training (18.2%) loss: 0.0247\n",
      "Training (27.3%) loss: 0.0127\n",
      "Training (36.4%) loss: 0.0110\n",
      "Training (45.6%) loss: 0.0082\n",
      "Training (54.7%) loss: 0.0051\n",
      "Training (63.8%) loss: 0.0025\n",
      "Training (73.0%) loss: 0.0023\n",
      "Training (82.1%) loss: 0.0016\n",
      "Training (91.2%) loss: 0.0068\n",
      "Epoch [30/40]\n",
      "Training (9.0%) loss: 0.0070\n",
      "Training (18.2%) loss: 0.0034\n",
      "Training (27.3%) loss: 0.0049\n",
      "Training (36.4%) loss: 0.0152\n",
      "Training (45.6%) loss: 0.0047\n",
      "Training (54.7%) loss: 0.0073\n",
      "Training (63.8%) loss: 0.0092\n",
      "Training (73.0%) loss: 0.0813\n",
      "Training (82.1%) loss: 0.0758\n",
      "Training (91.2%) loss: 0.0130\n",
      "Epoch [31/40]\n",
      "Training (9.0%) loss: 0.0576\n",
      "Training (18.2%) loss: 0.0144\n",
      "Training (27.3%) loss: 0.0077\n",
      "Training (36.4%) loss: 0.0087\n",
      "Training (45.6%) loss: 0.0223\n",
      "Training (54.7%) loss: 0.0270\n",
      "Training (63.8%) loss: 0.0129\n",
      "Training (73.0%) loss: 0.0035\n",
      "Training (82.1%) loss: 0.0085\n",
      "Training (91.2%) loss: 0.0033\n",
      "Epoch [32/40]\n",
      "Training (9.0%) loss: 0.0018\n",
      "Training (18.2%) loss: 0.0031\n",
      "Training (27.3%) loss: 0.0017\n",
      "Training (36.4%) loss: 0.0013\n",
      "Training (45.6%) loss: 0.0015\n",
      "Training (54.7%) loss: 0.0017\n",
      "Training (63.8%) loss: 0.0011\n",
      "Training (73.0%) loss: 0.0006\n",
      "Training (82.1%) loss: 0.0004\n",
      "Training (91.2%) loss: 0.0005\n",
      "Epoch [33/40]\n",
      "Training (9.0%) loss: 0.0005\n",
      "Training (18.2%) loss: 0.0005\n",
      "Training (27.3%) loss: 0.0004\n",
      "Training (36.4%) loss: 0.0004\n",
      "Training (45.6%) loss: 0.0004\n",
      "Training (54.7%) loss: 0.0003\n",
      "Training (63.8%) loss: 0.0003\n",
      "Training (73.0%) loss: 0.0002\n",
      "Training (82.1%) loss: 0.0002\n",
      "Training (91.2%) loss: 0.0003\n",
      "Epoch [34/40]\n",
      "Training (9.0%) loss: 0.0002\n",
      "Training (18.2%) loss: 0.0002\n",
      "Training (27.3%) loss: 0.0003\n",
      "Training (36.4%) loss: 0.0002\n",
      "Training (45.6%) loss: 0.0002\n",
      "Training (54.7%) loss: 0.0002\n",
      "Training (63.8%) loss: 0.0001\n",
      "Training (73.0%) loss: 0.0002\n",
      "Training (82.1%) loss: 0.0001\n",
      "Training (91.2%) loss: 0.0002\n",
      "Epoch [35/40]\n",
      "Training (9.0%) loss: 0.0001\n",
      "Training (18.2%) loss: 0.0001\n",
      "Training (27.3%) loss: 0.0001\n",
      "Training (36.4%) loss: 0.0001\n",
      "Training (45.6%) loss: 0.0001\n",
      "Training (54.7%) loss: 0.0001\n",
      "Training (63.8%) loss: 0.0001\n",
      "Training (73.0%) loss: 0.0001\n",
      "Training (82.1%) loss: 0.0001\n",
      "Training (91.2%) loss: 0.0001\n",
      "Epoch [36/40]\n",
      "Training (9.0%) loss: 0.0001\n",
      "Training (18.2%) loss: 0.0001\n",
      "Training (27.3%) loss: 0.0001\n",
      "Training (36.4%) loss: 0.0001\n",
      "Training (45.6%) loss: 0.0001\n",
      "Training (54.7%) loss: 0.0001\n",
      "Training (63.8%) loss: 0.0001\n",
      "Training (73.0%) loss: 0.0001\n",
      "Training (82.1%) loss: 0.0001\n",
      "Training (91.2%) loss: 0.0001\n",
      "Epoch [37/40]\n",
      "Training (9.0%) loss: 0.0001\n",
      "Training (18.2%) loss: 0.0001\n",
      "Training (27.3%) loss: 0.0001\n",
      "Training (36.4%) loss: 0.0001\n",
      "Training (45.6%) loss: 0.0001\n",
      "Training (54.7%) loss: 0.0001\n",
      "Training (63.8%) loss: 0.0000\n",
      "Training (73.0%) loss: 0.0001\n",
      "Training (82.1%) loss: 0.0000\n",
      "Training (91.2%) loss: 0.0000\n",
      "Epoch [38/40]\n",
      "Training (9.0%) loss: 0.0000\n",
      "Training (18.2%) loss: 0.0000\n",
      "Training (27.3%) loss: 0.0000\n",
      "Training (36.4%) loss: 0.0000\n",
      "Training (45.6%) loss: 0.0000\n",
      "Training (54.7%) loss: 0.0000\n",
      "Training (63.8%) loss: 0.0000\n",
      "Training (73.0%) loss: 0.0000\n",
      "Training (82.1%) loss: 0.0000\n",
      "Training (91.2%) loss: 0.0000\n",
      "Epoch [39/40]\n",
      "Training (9.0%) loss: 0.0000\n",
      "Training (18.2%) loss: 0.0000\n",
      "Training (27.3%) loss: 0.0000\n",
      "Training (36.4%) loss: 0.0000\n",
      "Training (45.6%) loss: 0.0000\n",
      "Training (54.7%) loss: 0.0000\n",
      "Training (63.8%) loss: 0.0000\n",
      "Training (73.0%) loss: 0.0000\n",
      "Training (82.1%) loss: 0.0000\n",
      "Training (91.2%) loss: 0.0000\n",
      "Epoch [40/40]\n",
      "Training (9.0%) loss: 0.0000\n",
      "Training (18.2%) loss: 0.0000\n",
      "Training (27.3%) loss: 0.0000\n",
      "Training (36.4%) loss: 0.0000\n",
      "Training (45.6%) loss: 0.0000\n",
      "Training (54.7%) loss: 0.0000\n",
      "Training (63.8%) loss: 0.0000\n",
      "Training (73.0%) loss: 0.0000\n",
      "Training (82.1%) loss: 0.0000\n",
      "Training (91.2%) loss: 0.0000\n"
     ]
    }
   ],
   "source": [
    "encoder_model = Encoder(input_lang.n_words, 128).to(device)\n",
    "decoder_model = Decoder(128, output_lang.n_words).to(device)\n",
    "\n",
    "train(encoder_model, decoder_model, n_epochs=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "83dbf90b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-18T14:39:36.545562Z",
     "iopub.status.busy": "2025-10-18T14:39:36.545075Z",
     "iopub.status.idle": "2025-10-18T14:39:36.552256Z",
     "shell.execute_reply": "2025-10-18T14:39:36.551386Z"
    },
    "id": "8e2c44d0",
    "papermill": {
     "duration": 0.033331,
     "end_time": "2025-10-18T14:39:36.553753",
     "exception": false,
     "start_time": "2025-10-18T14:39:36.520422",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "\n",
    "    input_tensor = sentence2tensor(input_lang, sentence)\n",
    "    encoder_hidden = encoder.init_hidden()\n",
    "\n",
    "    for elem in input_tensor:\n",
    "        encoder_output, encoder_hidden = encoder(elem, encoder_hidden)\n",
    "\n",
    "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    decoded_words = []\n",
    "\n",
    "    for di in range(max_length):\n",
    "        decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "        _, topi = decoder_output.data.topk(1)\n",
    "\n",
    "        decoded_words.append(output_lang.index2word[topi.item()])\n",
    "\n",
    "        if topi.item() == EOS_token:\n",
    "            break\n",
    "\n",
    "        decoder_input = topi.squeeze().detach()\n",
    "\n",
    "    return decoded_words\n",
    "\n",
    "\n",
    "def predict_(encoder, decoder, dataset):\n",
    "    result = []\n",
    "\n",
    "    for _ in dataset:\n",
    "        result.append(evaluate(encoder, decoder, _)[:10])\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ac5582d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-18T14:39:36.602727Z",
     "iopub.status.busy": "2025-10-18T14:39:36.602087Z",
     "iopub.status.idle": "2025-10-18T14:39:36.612889Z",
     "shell.execute_reply": "2025-10-18T14:39:36.612024Z"
    },
    "id": "C2euTKsiW7O9",
    "papermill": {
     "duration": 0.036639,
     "end_time": "2025-10-18T14:39:36.614447",
     "exception": false,
     "start_time": "2025-10-18T14:39:36.577808",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_dataset = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9fc617ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-18T14:39:36.664265Z",
     "iopub.status.busy": "2025-10-18T14:39:36.663129Z",
     "iopub.status.idle": "2025-10-18T14:40:04.279880Z",
     "shell.execute_reply": "2025-10-18T14:40:04.279053Z"
    },
    "id": "b5e06197",
    "papermill": {
     "duration": 27.642782,
     "end_time": "2025-10-18T14:40:04.281590",
     "exception": false,
     "start_time": "2025-10-18T14:39:36.638808",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_prediction = predict_(encoder_model, decoder_model, test_dataset['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "308712f0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-18T14:40:04.330595Z",
     "iopub.status.busy": "2025-10-18T14:40:04.330288Z",
     "iopub.status.idle": "2025-10-18T14:40:04.336157Z",
     "shell.execute_reply": "2025-10-18T14:40:04.335071Z"
    },
    "id": "936f704c",
    "papermill": {
     "duration": 0.032106,
     "end_time": "2025-10-18T14:40:04.337682",
     "exception": false,
     "start_time": "2025-10-18T14:40:04.305576",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_prediction = [''.join(x) for x in test_prediction]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "536ebf4b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-18T14:40:04.387857Z",
     "iopub.status.busy": "2025-10-18T14:40:04.387528Z",
     "iopub.status.idle": "2025-10-18T14:40:04.393311Z",
     "shell.execute_reply": "2025-10-18T14:40:04.392449Z"
    },
    "id": "BtI9Xj947bUL",
    "papermill": {
     "duration": 0.032611,
     "end_time": "2025-10-18T14:40:04.394843",
     "exception": false,
     "start_time": "2025-10-18T14:40:04.362232",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_dataset['label'] = test_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6f5cd974",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-18T14:40:04.443364Z",
     "iopub.status.busy": "2025-10-18T14:40:04.443065Z",
     "iopub.status.idle": "2025-10-18T14:40:04.463345Z",
     "shell.execute_reply": "2025-10-18T14:40:04.462445Z"
    },
    "id": "7467be43",
    "papermill": {
     "duration": 0.046397,
     "end_time": "2025-10-18T14:40:04.465091",
     "exception": false,
     "start_time": "2025-10-18T14:40:04.418694",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_dataset[['id', 'label']].to_csv('submission.csv', index=None)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 13996909,
     "sourceId": 116754,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31153,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1147.654064,
   "end_time": "2025-10-18T14:40:06.953528",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-10-18T14:20:59.299464",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
